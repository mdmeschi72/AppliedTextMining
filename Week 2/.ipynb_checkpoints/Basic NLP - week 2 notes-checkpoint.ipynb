{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1887e4",
   "metadata": {},
   "source": [
    "# Basic Natural Language Processing - week 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd815382",
   "metadata": {},
   "source": [
    "# Natural Language\n",
    "---\n",
    "*Language used for everyday communication by humans, including comunicating via social media* \n",
    "- English\n",
    "- spanish etc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda28093",
   "metadata": {},
   "source": [
    "# Natural Language processing\n",
    "---\n",
    "- any copmutation, manipulation of natural language \n",
    "- Natural languages evolve \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925969f0",
   "metadata": {},
   "source": [
    "## NLP Tasks: A Broad Spectrum\n",
    "---\n",
    "- Counting words, frequency of words \n",
    "- Finding sentence boundaries \n",
    "- Part of speech tagging\n",
    "- parsing the sentence structure \n",
    "- identify semantic roles (whole is subject, object, and verb) \n",
    "- Identifying entity (named entity recognition) \n",
    "- Finding which pronout refers to which entity (coreference resolution) \n",
    "\n",
    "*Challenge is how to do this in efficient manner* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb956e2",
   "metadata": {},
   "source": [
    "## Basic Tasks with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258daed",
   "metadata": {},
   "source": [
    "### What is NLTK\n",
    "---\n",
    "- NLTK: Natural Language toolkit \n",
    "- Open source library in python \n",
    "- Has support for most NLP tasks \n",
    "- Provides access to numerours text copra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef01ac",
   "metadata": {},
   "source": [
    "### Getting text copra from nltk \n",
    "`import nltk`\n",
    "\n",
    "`nltk.download()`\n",
    "\n",
    "`from nltk.book import *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154c2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179cbd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffcf1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c557488",
   "metadata": {},
   "source": [
    "### Counting vocabulary of words \n",
    "---\n",
    "`text7`\n",
    "\n",
    "`sent7`\n",
    "\n",
    "`len(sent7)`\n",
    "\n",
    "`len(text7)`\n",
    "\n",
    "*unique words* \n",
    "`len(set(text7))` \n",
    "\n",
    "*first ten unique words* \n",
    "`list(set(text7))[:10]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c334800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "100676\n",
      "12408\n"
     ]
    }
   ],
   "source": [
    "text7\n",
    "sent7\n",
    "print(len(sent7))\n",
    "print(len(text7))\n",
    "print(len(set(text7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c563a",
   "metadata": {},
   "source": [
    "### Frequency of words \n",
    "---\n",
    "\n",
    "`dist = FreqDist(text7)`\n",
    "\n",
    "`len(dist)`\n",
    "\n",
    "`vocab1 = dist.keys()`     # gives the words\n",
    "\n",
    "`vocab1[:10]` # gives you unique words\n",
    "\n",
    "`dist[u'four']` # gives you the number of times the word four appears \n",
    "\n",
    "#Find words where len > 5 and it appears more than 100 items\n",
    "\n",
    "`freqwords = [w for w in vocab1 if len(w) > 5 and dist[w] > 100]`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6d3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary which has the key as the word and the value as the number of times it appears\n",
    "dist = FreqDist(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98616307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist) #number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f9b0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 = dist.keys() #gives the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6dc46fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre\n",
      "Vinken\n",
      ",\n",
      "61\n",
      "years\n",
      "old\n",
      "will\n",
      "join\n",
      "the\n",
      "board\n",
      "as\n"
     ]
    }
   ],
   "source": [
    "cnt = 0 \n",
    "for word in vocab1:\n",
    "    print (word)\n",
    "    cnt+=1\n",
    "    if cnt > 10:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e31e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[u'mark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00da89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqwords = [w for w in vocab1 if len(w) > 5 and dist[w] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e894721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['billion',\n",
       " 'company',\n",
       " 'president',\n",
       " 'because',\n",
       " 'market',\n",
       " 'million',\n",
       " 'shares',\n",
       " 'trading',\n",
       " 'program']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066c49a",
   "metadata": {},
   "source": [
    "# Normalization and Stemming \n",
    "---\n",
    "- Different forms of the same \"word\"\n",
    "> input1 = \"List listed lists listing listings\" \n",
    "\n",
    "#this is normalization\n",
    "\n",
    "`words1 = input1.lower().split(' ')`\n",
    "\n",
    "- Stemming\n",
    "*Find the root word, or the root form of any word* \n",
    "\n",
    "`porter = nltk.PorterStemmer()`\n",
    "\n",
    "`[porter.stem(t) for t in words]`\n",
    "[u'list', u'list', u'list', u'list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45fed754",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = ['List', 'listing', 'listed', 'lists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2815c9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listing', 'listed', 'lists']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = [w.lower() for w in input1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d20bb535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in input2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88934f",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "*type of stemming* \n",
    "*want to have the words that come out to be meaningful* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f75abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = nltk.corpus.movie_reviews.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "15662850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a130fe13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'coupl',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'parti',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmetization would keep the values that are valid words\n",
    "[porter.stem(m) for m in mr[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "986ec434",
   "metadata": {},
   "outputs": [],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cbd0aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couple',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an',\n",
       " 'accident',\n",
       " '.',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'dy',\n",
       " ',',\n",
       " 'but',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'continues',\n",
       " 'to',\n",
       " 'see',\n",
       " 'him',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " ',',\n",
       " 'and',\n",
       " 'ha',\n",
       " 'nightmare',\n",
       " '.',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'the',\n",
       " 'deal',\n",
       " '?',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'and',\n",
       " '\"',\n",
       " 'sorta',\n",
       " '\"',\n",
       " 'find',\n",
       " 'out',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'critique',\n",
       " ':',\n",
       " 'a',\n",
       " 'mind',\n",
       " '-',\n",
       " 'fuck',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'the',\n",
       " 'teen',\n",
       " 'generation',\n",
       " 'that',\n",
       " 'touch',\n",
       " 'on',\n",
       " 'a',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'idea',\n",
       " ',',\n",
       " 'but',\n",
       " 'present',\n",
       " 'it',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'bad',\n",
       " 'package',\n",
       " '.',\n",
       " 'which',\n",
       " 'is',\n",
       " 'what',\n",
       " 'make',\n",
       " 'this',\n",
       " 'review',\n",
       " 'an',\n",
       " 'even',\n",
       " 'harder',\n",
       " 'one',\n",
       " 'to',\n",
       " 'write',\n",
       " ',',\n",
       " 'since',\n",
       " 'i',\n",
       " 'generally',\n",
       " 'applaud',\n",
       " 'film',\n",
       " 'which',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'break',\n",
       " 'the',\n",
       " 'mold',\n",
       " ',',\n",
       " 'mess',\n",
       " 'with',\n",
       " 'your',\n",
       " 'head',\n",
       " 'and',\n",
       " 'such',\n",
       " '(',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '&',\n",
       " 'memento',\n",
       " ')',\n",
       " ',',\n",
       " 'but',\n",
       " 'there',\n",
       " 'are',\n",
       " 'good',\n",
       " 'and',\n",
       " 'bad',\n",
       " 'way',\n",
       " 'of',\n",
       " 'making',\n",
       " 'all',\n",
       " 'type',\n",
       " 'of',\n",
       " 'film',\n",
       " ',',\n",
       " 'and',\n",
       " 'these',\n",
       " 'folk',\n",
       " 'just',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'snag',\n",
       " 'this',\n",
       " 'one',\n",
       " 'correctly',\n",
       " '.',\n",
       " 'they',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'have',\n",
       " 'taken',\n",
       " 'this',\n",
       " 'pretty',\n",
       " 'neat',\n",
       " 'concept',\n",
       " ',',\n",
       " 'but',\n",
       " 'executed',\n",
       " 'it',\n",
       " 'terribly',\n",
       " '.',\n",
       " 'so',\n",
       " 'what',\n",
       " 'are',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'the',\n",
       " 'movie',\n",
       " '?',\n",
       " 'well',\n",
       " ',',\n",
       " 'it',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'simply',\n",
       " 'too',\n",
       " 'jumbled',\n",
       " '.',\n",
       " 'it',\n",
       " 'start',\n",
       " 'off',\n",
       " '\"',\n",
       " 'normal',\n",
       " '\"',\n",
       " 'but',\n",
       " 'then',\n",
       " 'downshift',\n",
       " 'into',\n",
       " 'this',\n",
       " '\"',\n",
       " 'fantasy',\n",
       " '\"',\n",
       " 'world',\n",
       " 'in',\n",
       " 'which',\n",
       " 'you',\n",
       " ',',\n",
       " 'a',\n",
       " 'an',\n",
       " 'audience',\n",
       " 'member',\n",
       " ',',\n",
       " 'have',\n",
       " 'no',\n",
       " 'idea',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'going',\n",
       " 'on',\n",
       " '.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'dream',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'character',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dead',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'others',\n",
       " 'who',\n",
       " 'look',\n",
       " 'like',\n",
       " 'the',\n",
       " 'dead',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'strange',\n",
       " 'apparition',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'disappearance',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'looooot',\n",
       " 'of',\n",
       " 'chase',\n",
       " 'scene',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'ton',\n",
       " 'of',\n",
       " 'weird',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'happen',\n",
       " ',',\n",
       " 'and',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'simply',\n",
       " 'not',\n",
       " 'explained',\n",
       " '.',\n",
       " 'now',\n",
       " 'i',\n",
       " 'personally',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'mind',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'unravel',\n",
       " 'a',\n",
       " 'film',\n",
       " 'every',\n",
       " 'now',\n",
       " 'and',\n",
       " 'then',\n",
       " ',',\n",
       " 'but',\n",
       " 'when',\n",
       " 'all',\n",
       " 'it',\n",
       " 'doe',\n",
       " 'is',\n",
       " 'give',\n",
       " 'me',\n",
       " 'the',\n",
       " 'same',\n",
       " 'clue',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " 'again',\n",
       " ',',\n",
       " 'i',\n",
       " 'get',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'fed',\n",
       " 'up',\n",
       " 'after',\n",
       " 'a',\n",
       " 'while',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'this',\n",
       " 'film',\n",
       " \"'\",\n",
       " 's',\n",
       " 'biggest',\n",
       " 'problem',\n",
       " '.',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'obviously',\n",
       " 'got',\n",
       " 'this',\n",
       " 'big',\n",
       " 'secret',\n",
       " 'to',\n",
       " 'hide',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'want',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'it',\n",
       " 'completely',\n",
       " 'until',\n",
       " 'it',\n",
       " 'final',\n",
       " 'five',\n",
       " 'minute',\n",
       " '.',\n",
       " 'and',\n",
       " 'do',\n",
       " 'they',\n",
       " 'make',\n",
       " 'thing',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'thrilling',\n",
       " 'or',\n",
       " 'even',\n",
       " 'engaging',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'meantime',\n",
       " '?',\n",
       " 'not',\n",
       " 'really',\n",
       " '.',\n",
       " 'the',\n",
       " 'sad',\n",
       " 'part',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'arrow',\n",
       " 'and',\n",
       " 'i',\n",
       " 'both',\n",
       " 'dig',\n",
       " 'on',\n",
       " 'flick',\n",
       " 'like',\n",
       " 'this',\n",
       " ',',\n",
       " 'so',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'figured',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'out',\n",
       " 'by',\n",
       " 'the',\n",
       " 'half',\n",
       " '-',\n",
       " 'way',\n",
       " 'point',\n",
       " ',',\n",
       " 'so',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'strangeness',\n",
       " 'after',\n",
       " 'that',\n",
       " 'did',\n",
       " 'start',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'sense',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'still',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'the',\n",
       " 'make',\n",
       " 'the',\n",
       " 'film',\n",
       " 'all',\n",
       " 'that',\n",
       " 'more',\n",
       " 'entertaining',\n",
       " '.',\n",
       " 'i',\n",
       " 'guess',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'with',\n",
       " 'movie',\n",
       " 'like',\n",
       " 'this',\n",
       " 'is',\n",
       " 'that',\n",
       " 'you',\n",
       " 'should',\n",
       " 'always',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'that',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'is',\n",
       " '\"',\n",
       " 'into',\n",
       " 'it',\n",
       " '\"',\n",
       " 'even',\n",
       " 'before',\n",
       " 'they',\n",
       " 'are',\n",
       " 'given',\n",
       " 'the',\n",
       " 'secret',\n",
       " 'password',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'your',\n",
       " 'world',\n",
       " 'of',\n",
       " 'understanding',\n",
       " '.',\n",
       " 'i',\n",
       " 'mean',\n",
       " ',',\n",
       " 'showing',\n",
       " 'melissa',\n",
       " 'sagemiller',\n",
       " 'running',\n",
       " 'away',\n",
       " 'from',\n",
       " 'vision',\n",
       " 'for',\n",
       " 'about',\n",
       " '20',\n",
       " 'minute',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'just',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " '!',\n",
       " '!',\n",
       " 'okay',\n",
       " ',',\n",
       " 'we',\n",
       " 'get',\n",
       " 'it',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'people',\n",
       " 'chasing',\n",
       " 'her',\n",
       " 'and',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'who',\n",
       " 'they',\n",
       " 'are',\n",
       " '.',\n",
       " 'do',\n",
       " 'we',\n",
       " 'really',\n",
       " 'need',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " 'again',\n",
       " '?',\n",
       " 'how',\n",
       " 'about',\n",
       " 'giving',\n",
       " 'u',\n",
       " 'different',\n",
       " 'scene',\n",
       " 'offering',\n",
       " 'further',\n",
       " 'insight',\n",
       " 'into',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'strangeness',\n",
       " 'going',\n",
       " 'down',\n",
       " 'in',\n",
       " 'the',\n",
       " 'movie',\n",
       " '?',\n",
       " 'apparently',\n",
       " ',',\n",
       " 'the',\n",
       " 'studio',\n",
       " 'took',\n",
       " 'this',\n",
       " 'film',\n",
       " 'away',\n",
       " 'from',\n",
       " 'it',\n",
       " 'director',\n",
       " 'and',\n",
       " 'chopped',\n",
       " 'it',\n",
       " 'up',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'show',\n",
       " '.',\n",
       " 'there',\n",
       " 'might',\n",
       " \"'\",\n",
       " 've',\n",
       " 'been',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'decent',\n",
       " 'teen',\n",
       " 'mind',\n",
       " '-',\n",
       " 'fuck',\n",
       " 'movie',\n",
       " 'in',\n",
       " 'here',\n",
       " 'somewhere',\n",
       " ',',\n",
       " 'but',\n",
       " 'i',\n",
       " 'guess',\n",
       " '\"',\n",
       " 'the',\n",
       " 'suit',\n",
       " '\"',\n",
       " 'decided',\n",
       " 'that',\n",
       " 'turning',\n",
       " 'it',\n",
       " 'into',\n",
       " 'a',\n",
       " 'music',\n",
       " 'video',\n",
       " 'with',\n",
       " 'little',\n",
       " 'edge',\n",
       " ',',\n",
       " 'would',\n",
       " 'make',\n",
       " 'more',\n",
       " 'sense',\n",
       " '.',\n",
       " 'the',\n",
       " 'actor',\n",
       " 'are',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'most',\n",
       " 'part',\n",
       " ',',\n",
       " 'although',\n",
       " 'wes',\n",
       " 'bentley',\n",
       " 'just',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'playing',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'character',\n",
       " 'that',\n",
       " 'he',\n",
       " 'did',\n",
       " 'in',\n",
       " 'american',\n",
       " 'beauty',\n",
       " ',',\n",
       " 'only',\n",
       " 'in',\n",
       " 'a',\n",
       " 'new',\n",
       " 'neighborhood',\n",
       " '.',\n",
       " 'but',\n",
       " 'my',\n",
       " 'biggest',\n",
       " 'kudos',\n",
       " 'go',\n",
       " 'out',\n",
       " 'to',\n",
       " 'sagemiller',\n",
       " ',',\n",
       " 'who',\n",
       " 'hold',\n",
       " 'her',\n",
       " 'own',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'film',\n",
       " ',',\n",
       " 'and',\n",
       " 'actually',\n",
       " 'ha',\n",
       " 'you',\n",
       " 'feeling',\n",
       " 'her',\n",
       " 'character',\n",
       " \"'\",\n",
       " 's',\n",
       " 'unraveling',\n",
       " '.',\n",
       " 'overall',\n",
       " ',',\n",
       " 'the',\n",
       " 'film',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'stick',\n",
       " 'because',\n",
       " 'it',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'entertain',\n",
       " ',',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'confusing',\n",
       " ',',\n",
       " 'it',\n",
       " 'rarely',\n",
       " 'excites',\n",
       " 'and',\n",
       " 'it',\n",
       " 'feel',\n",
       " 'pretty',\n",
       " 'redundant',\n",
       " 'for',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'runtime',\n",
       " ',',\n",
       " 'despite',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'cool',\n",
       " 'ending',\n",
       " 'and',\n",
       " 'explanation',\n",
       " 'to',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'craziness',\n",
       " 'that',\n",
       " 'came',\n",
       " 'before',\n",
       " 'it',\n",
       " '.',\n",
       " 'oh',\n",
       " ',',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'way',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'horror',\n",
       " 'or',\n",
       " 'teen',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'just',\n",
       " 'packaged',\n",
       " 'to',\n",
       " 'look',\n",
       " 'that',\n",
       " 'way',\n",
       " 'because',\n",
       " 'someone',\n",
       " 'is',\n",
       " 'apparently',\n",
       " 'assuming',\n",
       " 'that',\n",
       " 'the',\n",
       " 'genre',\n",
       " 'is',\n",
       " 'still',\n",
       " 'hot',\n",
       " 'with',\n",
       " 'the',\n",
       " 'kid',\n",
       " '.',\n",
       " 'it',\n",
       " 'also',\n",
       " 'wrapped',\n",
       " 'production',\n",
       " 'two',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shelf',\n",
       " 'ever',\n",
       " 'since',\n",
       " '.',\n",
       " 'whatever',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'skip',\n",
       " 'it',\n",
       " '!',\n",
       " 'where',\n",
       " \"'\",\n",
       " 's',\n",
       " 'joblo',\n",
       " 'coming',\n",
       " 'from',\n",
       " '?',\n",
       " 'a',\n",
       " 'nightmare',\n",
       " 'of',\n",
       " 'elm',\n",
       " 'street',\n",
       " '3',\n",
       " '(',\n",
       " '7',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'blair',\n",
       " 'witch',\n",
       " '2',\n",
       " '(',\n",
       " '7',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'crow',\n",
       " '(',\n",
       " '9',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'crow',\n",
       " ':',\n",
       " 'salvation',\n",
       " '(',\n",
       " '4',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '(',\n",
       " '10',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'memento',\n",
       " '(',\n",
       " '10',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'others',\n",
       " '(',\n",
       " '9',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " '-',\n",
       " 'stir',\n",
       " 'of',\n",
       " 'echo',\n",
       " '(',\n",
       " '8',\n",
       " '/',\n",
       " '10',\n",
       " ')',\n",
       " 'the',\n",
       " 'happy',\n",
       " 'bastard',\n",
       " \"'\",\n",
       " 's',\n",
       " 'quick',\n",
       " 'movie',\n",
       " 'review',\n",
       " 'damn',\n",
       " 'that',\n",
       " 'y2k',\n",
       " 'bug',\n",
       " '.',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'got',\n",
       " 'a',\n",
       " 'head',\n",
       " 'start',\n",
       " 'in',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'starring',\n",
       " 'jamie',\n",
       " 'lee',\n",
       " 'curtis',\n",
       " 'and',\n",
       " 'another',\n",
       " 'baldwin',\n",
       " 'brother',\n",
       " '(',\n",
       " 'william',\n",
       " 'this',\n",
       " 'time',\n",
       " ')',\n",
       " 'in',\n",
       " 'a',\n",
       " 'story',\n",
       " 'regarding',\n",
       " 'a',\n",
       " 'crew',\n",
       " 'of',\n",
       " 'a',\n",
       " 'tugboat',\n",
       " 'that',\n",
       " 'come',\n",
       " 'across',\n",
       " 'a',\n",
       " 'deserted',\n",
       " 'russian',\n",
       " 'tech',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'ha',\n",
       " 'a',\n",
       " 'strangeness',\n",
       " 'to',\n",
       " 'it',\n",
       " 'when',\n",
       " 'they',\n",
       " 'kick',\n",
       " 'the',\n",
       " 'power',\n",
       " 'back',\n",
       " 'on',\n",
       " '.',\n",
       " 'little',\n",
       " 'do',\n",
       " 'they',\n",
       " 'know',\n",
       " 'the',\n",
       " 'power',\n",
       " 'within',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'going',\n",
       " 'for',\n",
       " 'the',\n",
       " 'gore',\n",
       " 'and',\n",
       " 'bringing',\n",
       " 'on',\n",
       " 'a',\n",
       " 'few',\n",
       " 'action',\n",
       " 'sequence',\n",
       " 'here',\n",
       " 'and',\n",
       " 'there',\n",
       " ',',\n",
       " 'virus',\n",
       " 'still',\n",
       " 'feel',\n",
       " 'very',\n",
       " 'empty',\n",
       " ',',\n",
       " 'like',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'going',\n",
       " 'for',\n",
       " 'all',\n",
       " 'flash',\n",
       " 'and',\n",
       " 'no',\n",
       " 'substance',\n",
       " '.',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'why',\n",
       " 'the',\n",
       " 'crew',\n",
       " 'wa',\n",
       " 'really',\n",
       " 'out',\n",
       " 'in',\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WNlemma.lemmatize(t) for t in mr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e959b8",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49b18502",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = \"Children shoudn't drink a sugary drink before bed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2396402c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children', \"shoudn't\", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "444800c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'shoud',\n",
       " \"n't\",\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice n't is a token \n",
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47cb8e8",
   "metadata": {},
   "source": [
    "# Sentence splitting \n",
    "*how would you split sentences from a long text string?* \n",
    "*Not all periods end sentences* \n",
    "## NLTK has sentence splitter\n",
    "*yields a list of sentences* \n",
    "\n",
    "`nltk.sent_tokenize(sents)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc1bdad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text12 = \"This is the first sentence.  A gallon of milk in the U.S. costs $2.99.  Is this the third sentence?  Yes it is!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "09803bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5419346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d8f8671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.',\n",
       " 'A gallon of milk in the U.S. costs $2.99.',\n",
       " 'Is this the third sentence?',\n",
       " 'Yes it is!']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b4934",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "---\n",
    "- nltk provides tokenizatioin and lemmetization\n",
    "- counting words and frequency of words \n",
    "- finding sentence boundaries \n",
    "- contains lots of text corpra to investigate and expirement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f258c5",
   "metadata": {},
   "source": [
    "# Advanced NLP tasks with NLTK\n",
    "---\n",
    "*covering the following in the video* \n",
    "- part of speech tagging\n",
    "- parsing the sentence structure \n",
    "\n",
    "*all other nlp functions* \n",
    "- Counting words, counting frequency of words\n",
    "- finding sentence boundaries \n",
    "- identifying semantic role labeling\n",
    "- named entity recognition \n",
    "- Co-referene and pronoun resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28801e1b",
   "metadata": {},
   "source": [
    "## Part of speech (POS) tagging\n",
    "---\n",
    "* nouns verbs adjectives\n",
    "* many more tags (conjunction, cardinal, determiner, preposition, modal, possesive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70700692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b40f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split sentence into wor\n",
    "text13 = nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dbd32003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'shoud',\n",
       " \"n't\",\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "72021d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children', 'NNP'),\n",
       " ('shoud', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('drink', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('sugary', 'JJ'),\n",
       " ('drink', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('bed', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find pos - gives list of tuples \n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883724a8",
   "metadata": {},
   "source": [
    "# Ambiguity in POS tagging\n",
    "---\n",
    "- abiguity is common in English \n",
    "\n",
    "*Visiting aunts can be a nuisance.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72969b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text14 = nltk.word_tokenize(\"Visiting aunts can be a nuisance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84793a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Visiting', 'VBG'),\n",
       " ('aunts', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('nuisance', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7f1ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb352cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6faf0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c4aa3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate - Visiting 'JJ' - adjective, going to visit aunts is a nuisance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5100e1",
   "metadata": {},
   "source": [
    "## Parsing sentence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d1b26ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffdac7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create context free grammar \n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "baf3d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5dc1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = parser.parse_all(text15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "48f6c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffe789",
   "metadata": {},
   "source": [
    "## Ambiguity in parsing\n",
    "*I saw the man with the telescope.*\n",
    "\n",
    "- To which entity does the preposition apply?  Is it that we saw the man who had a telescope, or did we have the telescope when we saw the man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e00dddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text16 = nltk.word_tokenize(\"I saw the man with the telescope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c859a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_tel = nltk.data.load('mygrammar4.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef2c6598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 13 productions>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6206002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar_tel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "14b037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = parser.parse_all(text16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "54297fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "50870c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (DT the) (N man)))\n",
      "    (PP (P with) (NP (DT the) (N telescope)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (DT the) (N man) (PP (P with) (NP (DT the) (N telescope))))))\n"
     ]
    }
   ],
   "source": [
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fba24",
   "metadata": {},
   "source": [
    "## NLTK and Parse Tree collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0c1c9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "43ce8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "text17 = treebank.parsed_sents('wsj_0001.mrg')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "81b93989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "print(text17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a9999",
   "metadata": {},
   "source": [
    "# POS tagging & parsing complexity\n",
    "--- \n",
    "*Uncommon usage of words* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5bcf914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text18 = nltk.word_tokenize(\"The old man the boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7345c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1609aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "33a4cb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colorless', 'NNP'),\n",
       " ('green', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('sleep', 'VBP'),\n",
       " ('furiously', 'RB')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97a506",
   "metadata": {},
   "source": [
    "# take home concepts\n",
    "---\n",
    "- POS tagging provides insights into the word classes/types in a sentence\n",
    "- parsing the grammatical sructures helps derive meaning \n",
    "- both tasks are difficult, liguistic ambiguity increases the difficulty even more \n",
    "- better models could be learned with supervised training\n",
    "- nltk provides access to tools and dadta for training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae05bcc",
   "metadata": {},
   "source": [
    "# Classification of Text\n",
    "*Supervised learning for text* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2696c6",
   "metadata": {},
   "source": [
    "## What is classification? \n",
    "---\n",
    "- Given a set of classes\n",
    "- Assign class label to an input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b97604",
   "metadata": {},
   "source": [
    "## Examples of text classification\n",
    "---\n",
    "- Topic identification \n",
    "- Spam detection \n",
    "- Sentiment analysis (is movie review positive or negative) \n",
    "- Spelling correction: whether or weather, color or colour "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655c2df",
   "metadata": {},
   "source": [
    "## Supervised Learning \n",
    "---\n",
    "- humans learn from past experiences, machines learn from past instances! \n",
    "- Training phase - model is created\n",
    "    - labled instance\n",
    "    - feed to classification algorithm \n",
    "    - Build classification model\n",
    "- Inference phase\n",
    "    - Create labels for input data \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d564f",
   "metadata": {},
   "source": [
    "## Supervised Classification \n",
    "---\n",
    "- learn classification model on properties (\"features\") andtheirimportance (\"weights\") from labeled instances \n",
    "- X: Setof attributes or features { x1, x2, x3,...,xn) \n",
    "    - email - where does it come from\n",
    "    - text - does it contain the word 'prince' \n",
    "- y: A \"class\" label from the label set Y = {y1, y2, ...,yk}\n",
    "\n",
    "*Apply model on new instances to predict the label* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4ade9",
   "metadata": {},
   "source": [
    "## Supervised Learning - Phases and datasets\n",
    "---\n",
    "- Labeled dataset\n",
    "    - divided into training data\n",
    "    - validation data - test effectiveness of the model \n",
    "    \n",
    "- Unlabeled dataset\n",
    "    - do further testing of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba440cd6",
   "metadata": {},
   "source": [
    "# Classification paradigms\n",
    "---\n",
    "- Where there are only two possible classes; |Y| = 2: \n",
    "\n",
    "**BINARY CLASSIFICATION**\n",
    "        \n",
    "- Where there are more than two possible classes; |Y| > 2: \n",
    "\n",
    "**MULTI-CLASS CLASSIFICATION** \n",
    "        \n",
    " - When data instances can have two or more labels: \n",
    " \n",
    "**MULTI-LABEL CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0fb24",
   "metadata": {},
   "source": [
    "# Questions to ask in supervised learning \n",
    "---\n",
    "- Training phase\n",
    "    - what are the features?  How do you represent them?\n",
    "    - what is the classification model/algo?\n",
    "    - what are the model parameters? \n",
    "    \n",
    "- Inference Phase\n",
    "    - What is the expected performance?  What is a good measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f00b32",
   "metadata": {},
   "source": [
    "# Identifying features from text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e6d24",
   "metadata": {},
   "source": [
    "# Why is textual data unique? \n",
    "---\n",
    "- Textual data presents a unique set of challenges \n",
    "- All the information that you need is in the text \n",
    "- But features can be pulled from text at different granularities! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0af21",
   "metadata": {},
   "source": [
    "## Type of textual features (I)\n",
    "---\n",
    "- words\n",
    "    - By far the most used for features \n",
    "    - Handling commonly-occurring words: stop words\n",
    "    - Normalization: Make lower case vs.leave as-is \n",
    "    - stemming / lemmatization\n",
    "- characteristics of words\n",
    "    - captalized? \n",
    "    - parts of speach of words in a sentence \n",
    "    - gramatical structure, sentence parsing \n",
    "    - Grouping words of similar meaning (buy/purchase) - synonyms (Mr., Ms., Dr.,), dates (recognize with re) \n",
    "- depending upon classification of tasks features may come from inside words and word sequences\n",
    "    - bigrams, trigrams, n-grams: \"White House\"  \"Saturday Night Live\" \n",
    "    - character sub-sequences in words: \"ing\", \"ion\", ... \n",
    "    - \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
